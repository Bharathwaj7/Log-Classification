# Log Classification System

## ğŸ“‹ Overview

A hybrid **Log Classification System** designed for a US-based client at ATCK Technologies. This solution automates log monitoring by combining ruleâ€‘based, machineâ€‘learning, and LLMâ€‘driven approaches to accurately categorize incoming logs in real time, reducing downtime, manual effort, and security risks.

## âœ¨ Features

- **Regexâ€‘Based Classification**  
  Quickly detect and label logs matching fixed patterns via Python regular expressions.  
- **BERT + Logistic Regression**  
  Leverage BERT embeddings with a lightweight PyTorch logistic regression layer for patterns with ample training data.  
- **LLMâ€‘Fallback Classification**  
  Employ a Large Language Model (e.g., LLaMA) when training samples are scarce or patterns are too complex.  
- **FastAPI Backend**  
  Serve classification endpoints over a highâ€‘performance REST API.  
- **Extensible & Configurable**  
  Easily add new regex rules, retrain BERT models, or swap in different LLMs with minimal code changes.  
- **Realâ€‘Time Monitoring**  
  Aggregate and classify logs on the fly for immediate alerting and dashboard integration.

## ğŸ”§ Technical Stack

- **Deep Learning & NLP**  
  - BERT (via Hugging Face Transformers)  
  - LLaMA or alternative LLM  
  - PyTorch for embedding & logistic regression  
- **Ruleâ€‘Based**  
  - Python `re` module for regular expressions  
- **API Layer**  
  - FastAPI with Uvicorn  
- **Development Environment**  
  - PyCharm Professional (3â€‘month free trial available)  
- **Data Handling & Clustering**  
  - Pandas, NumPy  
  - scikitâ€‘learnâ€™s DBSCAN for pattern discovery  

## ğŸš€ Getting Started

### 1. Clone the Repo  
```bash
git clone https://github.com/yourusername/log-classification-system.git
cd log-classification-system
```

### 2. Create & Activate Virtual Env  
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies  
```bash
pip install -r requirements.txt
```

### 4. Prepare Data  
- Place your log files (CSV/Excel) into `data/`  
- Ensure columns: `timestamp`, `source`, `message`, `target_label`  

### 5. Index Regex Patterns  
```bash
python scripts/cluster_and_generate_regex.py   --input data/raw_logs.xlsx   --output configs/regex_patterns.json
```

## ğŸ–¥ï¸ How to Use

1. **Run the Classifier**  
   ```bash
   uvicorn app.main:app --reload
   ```
2. **Upload & Classify Logs**  
   - POST your log batch to `/classify/batch`  
   - GET classification results at `/classify/{log_id}`  
3. **Monitor in Real Time**  
   - Connect to WebSocket `/ws/logs` for continuous stream  

## ğŸ§  How It Works

1. **Log Ingestion**  
   Logs are received in CSV/Excel and parsed into a DataFrame.  
2. **Pattern Discovery**  
   DBSCAN clustering identifies recurring message structures to seed regex rules.  
3. **Hybrid Classification Pipeline**  
   - **Step 1: Regex Engine**  
     Match against predefined patterns for deterministic categories.  
   - **Step 2: BERT Model**  
     For unmatched logs with â‰¥N samples, encode with BERT and classify via logistic regression.  
   - **Step 3: LLM Fallback**  
     For outliers or underâ€‘sampled categories, query the LLM with a prompt template for final labeling.  
4. **Result Aggregation**  
   Responses from each stage are merged, with confidence scores, and stored in the metadata index.

## ğŸ“ Project Structure

```
log-classification-system/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ log_classifier.joblib       # Trained BERT+LR model
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ dataset/                    # Raw and labeled log files
â”‚   â””â”€â”€ training.ipynb              # Exploration & prototyping notebook
â”œâ”€â”€ classify.py                     # CLI for single/batch classification
â”œâ”€â”€ main.py                         # Entry point for model training & utils
â”œâ”€â”€ processor_bert.py               # BERT embedding & LR classification
â”œâ”€â”€ processor_llm.py                # LLMâ€based classification logic
â”œâ”€â”€ processor_regex.py              # Regex pattern generation & matching
â”œâ”€â”€ server.py                       # FastAPI application
â”œâ”€â”€ configs/                        # Configuration files (e.g. regex patterns)
â”œâ”€â”€ requirements.txt
â””â”€â”€ LICENSE                         # MIT License
```

## ğŸ› ï¸ Customization

- **Add New Regex Rules**  
  Update `configs/regex_patterns.json` or rerun the clustering script with new data.  
- **Retrain BERT Model**  
  Modify `models/bert_classifier.py` to tweak hyperparameters or swap in a different transformer.  
- **Swap LLM**  
  In `models/llm_classifier.py`, change the model endpoint or prompt template to use GPTâ€‘4, LLaMA, etc.  

## ğŸ“Š Performance Considerations

- **Batch Inference**  
  Group log entries to amortize model loading overhead.  
- **GPU Acceleration**  
  Use a CUDAâ€‘enabled machine for BERT embedding and LLM calls.  
- **Caching & Async I/O**  
  Leverage FastAPIâ€™s async features and an inâ€‘memory cache for repeated queries.  
- **Scalability**  
  Deploy behind a loadâ€‘balancer; consider FAAS for sporadic LLM fallback calls.

## ğŸ“ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.
